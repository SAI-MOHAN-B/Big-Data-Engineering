{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6618300-8a55-43ca-9dbd-77985ca1d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b369ff-98b9-4a3a-a0f0-42ac56235b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b37d43-086a-48fa-b29e-c66a1f82d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/17 13:26:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/17 13:26:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/06/17 13:26:17 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 52813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Different-Caching\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475b3cf3-f1ee-4f85-9390-af32f18aaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplicationCodeOptimization.ipynb  ReduceByKey.ipynb\n",
      "BroadcastJoins.ipynb               Repartiton-Coalesce.ipynb\n",
      "Caching-Table.ipynb                Spark-Table.ipynb\n",
      "Caching-performance.ipynb          SparkOptimizationcode.txt\n",
      "Count.txt                          departments.csv\n",
      "DataFrame.ipynb                    employees.csv\n",
      "Different-caching.ipynb            \u001b[34moutput_data\u001b[m\u001b[m/\n",
      "Distinct,Take.ipynb                \u001b[34moutput_data_parquet\u001b[m\u001b[m/\n",
      "Filter.ipynb                       \u001b[34moutput_folder\u001b[m\u001b[m/\n",
      "Group and Reduce By key.ipynb      \u001b[34mspark-warehouse\u001b[m\u001b[m/\n",
      "Joins.ipynb                        students.csv\n",
      "Pyspark-Get.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595bcb4d-f9a6-403f-9dcb-03b5850f9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdf = spark.read.format(\"csv\").option(\"inferSchema\",True).option(\"header\",True).load(\"employees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098bde23-7923-467f-bd78-9883ab3a5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deptdf = spark.read.format(\"csv\").option(\"inferSchema\",True).option(\"header\",True).load(\"departments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d339922-dd80-4a16-89b5-9d7374aa0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|  JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|SH_CLERK|  2600|            - |       124|           50|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------------+---------------+----------+-----------+\n",
      "|DEPARTMENT_ID|DEPARTMENT_NAME|MANAGER_ID|LOCATION_ID|\n",
      "+-------------+---------------+----------+-----------+\n",
      "|           10| Administration|       200|       1700|\n",
      "+-------------+---------------+----------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empdf.show(1)\n",
    "deptdf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17c172d0-53c2-428a-b476-d57fb871a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_df = empdf.select(\"employee_id\",\"first_name\",\"last_name\",\"salary\").filter(\"salary>2600\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361b9840-880b-411c-9b50-3bbddee02713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empdf.select(\"employee_id\",\"first_name\",\"last_name\",\"salary\").filter(\"salary>2600\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb96ccc-120a-46a5-8522-a34345e11635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the logical plan changes\n",
    "# because the above statement cache doen't have the information of the salary having greater tahn 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebbd66bf-2443-4c32-8377-b5ba2b4505aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cache_df = empdf.select(\"employee_id\",\"first_name\",\"last_name\",\"salary\").filter(\"salary>10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8d22e8e-b0d7-41b1-9926-9fb18efa09eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cache_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f795a68b-1171-4652-8a65-d45afbe9154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply cache here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a474ab-2dd7-474b-8522-72ca1f29f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cache_df = empdf.select(\"employee_id\",\"first_name\",\"last_name\",\"salary\").filter(\"salary>10000\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "196d4193-32ab-4877-add7-abd64dbb5f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cache_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6fda3-75dd-4127-8e95-ce2d83d34883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79c82af2-a300-458c-9b31-b19b7a5a1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_cache = spark.sparkContext.textFile(\"count.txt\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd0bc05-b264-4c21-914b-6a191fe4d480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world hello world'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_cache.collect()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65d0d777-c429-4741-9783-db5e940ad5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd_cache.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "399f1efa-ebee-4d30-842d-bb572b0f931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.map(lambda x:(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8729ddcf-c316-48ad-946a-9eb8053c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = rdd4.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a59ecdc0-1ed8-4b69-bf4a-5c9ef3b75e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = rdd5.toDF([\"word\",\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c996fd05-5cca-4a54-bb87-1f6ebfd639a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   word|count|\n",
      "+-------+-----+\n",
      "|     to|    1|\n",
      "|   this|    2|\n",
      "|       |    1|\n",
      "|  hello|    2|\n",
      "|  world|    2|\n",
      "|welcome|    2|\n",
      "|    the|    1|\n",
      "|     is|    2|\n",
      "|      a|    2|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f1959-8bf2-4d8f-8f8c-66175d373bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
