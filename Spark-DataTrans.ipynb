{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f9a892-bfa1-43bb-97f2-ffec5371b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f756eff-3dde-42b8-922a-eacfaec68fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ec57d6-23cb-4fc6-bf57-68fc9b6acb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark =  SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21da2fc9-bba1-4d50-a5b4-31d157db38ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is New Volume\n",
      " Volume Serial Number is 70A0-36F4\n",
      "\n",
      " Directory of E:\\Jupyter notebook\n",
      "\n",
      "06/10/2024  03:48 PM    <DIR>          .\n",
      "06/10/2024  03:48 PM    <DIR>          ..\n",
      "06/10/2024  03:46 PM    <DIR>          .ipynb_checkpoints\n",
      "03/31/2024  04:49 AM             6,857 2012-summary.csv\n",
      "04/23/2024  01:21 PM    <DIR>          Darshil Spark\n",
      "04/01/2024  01:03 PM             2,360 Handling Missing values.ipynb\n",
      "04/02/2024  01:27 PM    <DIR>          Playstore-Project\n",
      "06/03/2024  01:46 PM    <DIR>          Practice\n",
      "06/10/2024  03:48 PM             2,713 Spark-DataTrans.ipynb\n",
      "               3 File(s)         11,930 bytes\n",
      "               6 Dir(s)  217,652,129,792 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a853d02b-a48b-437f-84df-7578b50c9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"inferSchema\",True).option(\"header\",True).load(\"2012-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d48f432-be8c-477d-b81f-1a16d46fc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81c150f-bd3a-44c0-9ffd-69585b9d59d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is New Volume\n",
      " Volume Serial Number is 70A0-36F4\n",
      "\n",
      " Directory of E:\\Jupyter notebook\n",
      "\n",
      "06/10/2024  03:54 PM    <DIR>          .\n",
      "06/10/2024  03:54 PM    <DIR>          ..\n",
      "06/10/2024  03:46 PM    <DIR>          .ipynb_checkpoints\n",
      "03/31/2024  04:49 AM            21,353 2010-summary.json\n",
      "03/31/2024  04:49 AM             6,857 2012-summary.csv\n",
      "04/23/2024  01:21 PM    <DIR>          Darshil Spark\n",
      "04/01/2024  01:03 PM             2,360 Handling Missing values.ipynb\n",
      "04/02/2024  01:27 PM    <DIR>          Playstore-Project\n",
      "06/03/2024  01:46 PM    <DIR>          Practice\n",
      "06/10/2024  03:52 PM             4,106 Spark-DataTrans.ipynb\n",
      "               4 File(s)         34,676 bytes\n",
      "               6 Dir(s)  217,652,101,120 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89985151-a534-4649-9ab0-13f9589e78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = spark.read.format(\"json\").load(\"2010-summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8f8d7b2-5cc3-440e-af9e-4f210db004e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23ca2ad-ca7b-4bad-9b40-7d5b26b83939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is New Volume\n",
      " Volume Serial Number is 70A0-36F4\n",
      "\n",
      " Directory of E:\\Jupyter notebook\n",
      "\n",
      "06/10/2024  04:23 PM    <DIR>          .\n",
      "06/10/2024  04:23 PM    <DIR>          ..\n",
      "06/10/2024  03:46 PM    <DIR>          .ipynb_checkpoints\n",
      "03/31/2024  04:49 AM            21,353 2010-summary.json\n",
      "03/31/2024  04:49 AM             6,857 2012-summary.csv\n",
      "04/23/2024  01:21 PM    <DIR>          Darshil Spark\n",
      "04/01/2024  01:03 PM             2,360 Handling Missing values.ipynb\n",
      "04/02/2024  01:27 PM    <DIR>          Playstore-Project\n",
      "06/03/2024  01:46 PM    <DIR>          Practice\n",
      "06/10/2024  04:23 PM             9,454 Spark-DataTrans.ipynb\n",
      "06/10/2024  04:25 PM                34 test.json\n",
      "06/10/2024  04:22 PM                83 test.json.txt\n",
      "               6 File(s)         40,141 bytes\n",
      "               6 Dir(s)  217,652,097,024 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "424f0b13-d28f-4b44-8b9d-1e889c4550e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = spark.read.option(\"samplingRatio\",0.4).json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad7dae16-7706-45d8-8157-585715c5ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://SAYONARA.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ba1cecef10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cc92c38-cad4-4304-9fb8-892a12cbf911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----+\n",
      "|  a|  b|  c|   d|\n",
      "+---+---+---+----+\n",
      "|  1|  3|  7|NULL|\n",
      "| 11| 13| 17|NULL|\n",
      "| 31| 33| 37|  71|\n",
      "+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84271209-09e7-4569-9cf9-76e3ce3d95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,ArrayType,MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bed76a5-3093-4cbb-8c4f-aa7d5c6eb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_schema = StructType([StructField(\"name\",StringType(),nullable=False),StructField(\"age\",IntegerType(),nullable=False),\n",
    "                            StructField(\"Subjects\",ArrayType(StringType()),nullable=False),StructField(\"Grades\",MapType(StringType(),StringType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adc7b492-e89c-4977-b1f0-c96c1ed13b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Alice\",30,[\"math\",\"science\"],{\"math\":\"A\",\"Science\":\"B\"}),(\"Mary\",31,[\"social\",\"science\"],{\"a\":\"A\",\"b\":\"B\"})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44a2f85d-0f7f-41e6-970f-896eaa690980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data,schema=nested_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21a7a2cc-e981-4cfb-90a2-6da500e1f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- Subjects: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Grades: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b62fe0a-7985-4c12-a1db-694a61f71c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------------+-------------------------+\n",
      "|name |age|Subjects         |Grades                   |\n",
      "+-----+---+-----------------+-------------------------+\n",
      "|Alice|30 |[math, science]  |{Science -> B, math -> A}|\n",
      "|Mary |31 |[social, science]|{a -> A, b -> B}         |\n",
      "+-----+---+-----------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18122c62-175d-43c9-af40-a7646d718ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b725a-ec3d-43fd-88fb-513440cc54ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f29c0-0fed-4a45-8b71-6701428cce2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51590705-611d-4671-9e65-06124ddccd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4d060-f878-46f7-b65e-b82e43071d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90255000-7394-49b7-aba9-9d26159f0d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a5421-4c7e-4a79-b646-dab569da166b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af448a5-4b5e-44b6-98d5-b8c188087af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af0d47-7bf3-48ba-bb56-89cff309576a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21acd076-bcf1-434f-88ea-a1687f7d1339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c351767-af18-40aa-a76f-e98a832705aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7352a-1c0c-4dca-afc7-88d0d372ae49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
